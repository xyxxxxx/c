现代计算机存储和处理的信息以二值信号表示。当我们把位组合在一起，再加上某种**解释（interpretation）**，即赋予不同的可能位模式以含义，就能够表示任何有限集合的元素。

我们将研究三种最重要的数字表示：**无符号（unsigned）**编码基于传统的二进制表示法，表示大于等于0的数字；**补码（two’s-complement）**编码是表示有符号整数的最常见的方式；**浮点数（floating-point）**编码是表示实数的科学计数法的以2为基数的版本。计算机用不同的表示方法实现算术运算。

计算机的表示法用有限数量的位来对应一个数字编码，因此当结果太大以至于不能表示时，某些运算就会**溢出（overflow）**。一处会导致令人吃惊的后果。

浮点运算有完全不同的数学属性。浮点运算是不可结合的，在大多数机器上，C表达式`(3.14+1e20)-1e20`求得的值会是0.0，而`3.14+(1e20-1e20)`求得的值会是3.14。整数运算和浮点运算的不同的数学属性来源于它们处理数字表示有限性的方式不同——整数的表示虽然只能编码一个相对较小的数值范围。但是这种表示是精确的；浮点数虽然可以编码一个较大的数值范围，但是这种表示只是近似的。

通过研究数字的实际表示，我们能够了解可以表示的值的范围和不同算术运算的属性。为了使编写的程序能在全部数值范围内正确工作，而且具有可以跨越不同机器、操作系统和编译器组合的可移植性，了解这种属性是非常重要的。此外，大量计算机的安全漏洞都是由于计算机运算的微妙细节引发的。





# 信息存储

## 十六进制表示法

**十六进制（hexadecimal）**

在C语言中，以0x或0X开头的数字常量被认为是十六进制的值。字符A-F可以是大写，小写，或大小写混合，比如`0xFa1D37b`。

进制转换



## 字数据大小

每台计算机都有一个**字长（word size）**，指明指针数据的标称大小（nominal size）。由于虚拟地址以字来编码，所以字长决定的最重要的系统参数就是虚拟地址空间的最大大小。对于字长为w位的机器而言，虚拟地址的范围是$$0\sim2^w-1$$，程序最多访问$2^w$个字节。32位字长的虚拟地址空间为4GB，64位字长的虚拟地址空间为16EB。大多数64位机器也可以运行32位机器编译的程序。

![](https://raw.githubusercontent.com/xyxxxxx/image/master/cxgjio5njyuiognwrj.PNG)

为了避免由于依赖典型大小和不同编译器设置带来的奇怪行为，ISO C99引入了一类数据类型，其数据大小是固定的，不随编译器和机器设置而变化，其中就有数据类型`int32_t`和`int64_t`，它们分别为4个字节和8个字节。

大部分数据类型都编码为有符号数值，除非有前缀关键字`unsigned`或对确定大小的数据类型使用了特定的无符号声明。数据类型`char`是一个例外。尽管大多数编译器和机器将它们视为有符号数，但C标准不保证这一点。

程序员应力图使他们的程序在不同的机器和编译器上可移植，可移植的一个方面就是使程序对不同数据类型的确切大小不敏感。从1980年左右到2010年左右，32位机器和32位程序是主流的组合，许多程序的编写都假设为32位程序的字节分配。随着64位机器的普及，在将这些程序移植到新机器上时，许多隐藏的对字长的依赖性就会显现出来成为错误。例如许多程序员假设一个声明为`int`类型的程序对象能被用来存储一个指针，这在大多数32位的机器上能正常工作，但在一台64位的机器上却会出现问题。



## 寻址和字节顺序

对于跨越多字节的程序对象，我们必须建立两个规则：这个对象的地址是什么，在内存中如何排列这些字节。在几乎所有的机器上，多字节对象都被存储为连续的字节序列，对象的地址为所使用字节中最小的地址。例如，假设一个类型为`int`的变量`x`的地址为`0x100`，也就是说地址表达式`&x`的值为`0x100`。那么`x`的4个字节将被存储在内存的`0x100`，`0x101`，`0x102`和`0x103`位置。

排列表示一个对象的字节有两个通用的规则。某些机器选择在内存中按照从最低有效字节到最高有效字节的顺序存储对象，而另一些机器从最高有效字节到最低有效字节的顺序存储对象。前一种规则称为**小端法（little endian）**，后一种规则称为**大端法（big endian）**。

假设变量`x`的类型为`int`，位于地址`0x100`处，其十六进制值为`0x01234567`，地址范围`0x100`\~`0x103`的字节顺序依赖于机器的类型。

![](https://raw.githubusercontent.com/xyxxxxx/image/master/cvnjkn45iotughjuiorw.PNG)

大多数Intel兼容机都只用小端模式，另一方面，IBM和Oracle的大多数机器则是按大端模式操作。许多比较新的微处理器是**双端法（bi-endian）**，也就是说可以把它们配置为大端或者小端的机器运行。然而实际情况是，一旦选择了特定操作系统，那么字节顺序也就固定下来。比如用于许多智能手机的ARM微处理器，其硬件可以按小端或大端两种模式操作，但是这些芯片上最常见的两种操作系统——Android和IOS——却只能运行于小端模式。

对于大多数应用程序员来说，其机器所使用的字节顺序是完全不可见的，无论为哪种类型的机器所编译的程序都会得到同样的结果。但有时候字节顺序会成为问题。首先是在不同类型的机器之间通过网络传送二进制数据时，一个常见的问题是当小端法机器产生的数据被发送到大端法机器或者相反时，接收程序会发现字里的字节成了反序的。为了避免这类问题，网络应用程序的代码编写必须遵守已建立的关于字节顺序的规则，以确保发送方机器将它的内部表示转换成了网络标准，而接收方机器则将网络标准转换为它的内部表示。

第二种情况是当阅读表示整数数据的字节序列时字节顺序也很重要。这通常发生在检查机器级程序时。作为一个示例，从某个文件摘出了由**反汇编器（disassembler）**生成的代码：

```
4004d3: 01 05 43 0b 20 00			add %eax,0x200b43(%rip)
```

十六进制字节串`01 05 43 0b 20 00`是一条指令的字节级表示，这条指令是把一个字长的数据加到一个值上，该值的存储地址由`0x200b43`加上当前程序计数器的值得到。这个序列的最后4个字节：`43 0b 20 00`即为地址`0x200b43`的相反顺序的显示。

第三种情况是当编写规避正常的类型的程序时。在C语言中，可以通过使用**强制类型转换（cast）**或**联合（union）**来允许一种数据类型引用另一种数据类型。大多数应用编程都强烈不推荐这种编码技巧，但是它们对系统级编程来说非常有用，甚至是必须的。如图展示了一段C代码，其使用强制类型转换来访问和打印不同程序对象的字节表示。

![](https://raw.githubusercontent.com/xyxxxxx/image/master/cvjio4tjio5ty2jgrwuiofeq.PNG)

在几种不同的机器上运行代码，得到下图所示的结果。

![](https://raw.githubusercontent.com/xyxxxxx/image/master/grjw8i5j23uiogrnfuy.PNG)

参数12345的十六进制表示为0x00003039，对于`int`类型的数据，除了字节顺序以外，我们在所有机器上都得到相同的结果。其中我们可以看到在Linux 32，Windows，Linux64上，最低有效字节值先输出，说明它们是小端法机器，而Sun是大端法机器。同样地，`float`数据的字节除了字节顺序以外也都是相同的。然而指针值却是完全不同的，不同的机器/操作系统使用不同的存储分配规则。一个值得注意的特性是Linux 32，Windows，Sun的机器使用4字节地址，而Linux64使用8字节地址。



## 表示字符串

C语言中字符串被编码为一个以null字符（`'\0'`）结尾的字符数组，每个字符都由某个标准编码表示，最常见的是ASCII字符码。字符串`"12345"`的字节表示为`31 32 33 34 35 00`。



## 表示代码

考虑下面的C函数：

```C
int sum(int x, int y) {
    return x + y
}
```

当我们在机器上编译时，生成如下字节表示的机器代码：

图

我们发现指令编码是不同的。不同的机器类型使用不同的且不兼容的指令和编码方式。即使是完全一样的程序，运行在不同的操作系统上也会有不同的编码规则，因此二进制代码是不兼容的。二进制代码很少能在不同机器和操作系统组合之间移植。



## 布尔代数简介

略



## C语言的位运算

略



## C语言的逻辑运算

略



## C语言的移位运算

左移将x向左移动k位，丢弃最高的k位，并在右端补k个0。右移类似，逻辑右移在左端补k个0，而算术右移在左端补k个最高有效位的值。

图

C语言标准并没有明确定义有符号数应该使用哪种类型的右移——算术右移和逻辑右移都可以，因此任何假设一种右移形式的代码都可能遇到可移植性问题。但实际上几乎所有的编译器和及其组合都对有符号数使用算术右移，而对于无符号数则必须是逻辑右移。





# 整数表示